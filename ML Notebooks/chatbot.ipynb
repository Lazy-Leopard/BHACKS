{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chatbot",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "P73DcwZ1jYnd",
        "outputId": "cb88bca7-e0c7-4513-e5ce-833d7efbc623"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "with open('symptoms.json') as f:\n",
        "  df = json.load(f)\n",
        "\n",
        "anip = pd.json_normalize(df['diseases'])\n",
        "anip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>symptoms</th>\n",
              "      <th>tests</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>breast cancer</td>\n",
              "      <td>[Lumps near breast or underarm, Swelling on br...</td>\n",
              "      <td>[Breast exam, Mammogram, Breast ultrasound, Br...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cardiovascular disease</td>\n",
              "      <td>[chest pain or pressure, shortness of breath, ...</td>\n",
              "      <td>[ECG, Holter monitoring, Echocardiogram, Stres...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>covid-19</td>\n",
              "      <td>[fever, dry cough, tiredness, aches &amp; pains, s...</td>\n",
              "      <td>[Viral Test, Antibody Test, Chest X-Ray]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>diabetes type 1</td>\n",
              "      <td>[increased thirst, increased hunger, excessive...</td>\n",
              "      <td>[Glycated haemoglobin (A1C) test, Random blood...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>diabetes type 2</td>\n",
              "      <td>[increased thirst, increased hunger, excessive...</td>\n",
              "      <td>[Glycated haemoglobin (A1C) test, Random blood...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>pneumonia</td>\n",
              "      <td>[coughing, fever, sweating or chills, shortnes...</td>\n",
              "      <td>[Blood tests, Chest X-ray, Pulse oximetry, Spu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     name  ...                                              tests\n",
              "0           breast cancer  ...  [Breast exam, Mammogram, Breast ultrasound, Br...\n",
              "1  cardiovascular disease  ...  [ECG, Holter monitoring, Echocardiogram, Stres...\n",
              "2                covid-19  ...           [Viral Test, Antibody Test, Chest X-Ray]\n",
              "3         diabetes type 1  ...  [Glycated haemoglobin (A1C) test, Random blood...\n",
              "4         diabetes type 2  ...  [Glycated haemoglobin (A1C) test, Random blood...\n",
              "5               pneumonia  ...  [Blood tests, Chest X-ray, Pulse oximetry, Spu...\n",
              "\n",
              "[6 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "IkDpd4BMOJ37",
        "outputId": "c3427ff2-f558-43b7-b5f7-b052c047a596"
      },
      "source": [
        "tejas = anip\n",
        "del tejas['tests']\n",
        "tejas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>symptoms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>breast cancer</td>\n",
              "      <td>[Lumps near breast or underarm, Swelling on br...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cardiovascular disease</td>\n",
              "      <td>[chest pain or pressure, shortness of breath, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>covid-19</td>\n",
              "      <td>[fever, dry cough, tiredness, aches &amp; pains, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>diabetes type 1</td>\n",
              "      <td>[increased thirst, increased hunger, excessive...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>diabetes type 2</td>\n",
              "      <td>[increased thirst, increased hunger, excessive...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>pneumonia</td>\n",
              "      <td>[coughing, fever, sweating or chills, shortnes...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     name                                           symptoms\n",
              "0           breast cancer  [Lumps near breast or underarm, Swelling on br...\n",
              "1  cardiovascular disease  [chest pain or pressure, shortness of breath, ...\n",
              "2                covid-19  [fever, dry cough, tiredness, aches & pains, s...\n",
              "3         diabetes type 1  [increased thirst, increased hunger, excessive...\n",
              "4         diabetes type 2  [increased thirst, increased hunger, excessive...\n",
              "5               pneumonia  [coughing, fever, sweating or chills, shortnes..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK7ZOA7lQsnZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "16290880-1ec1-44c8-c143-a90e20fe969e"
      },
      "source": [
        "tejas.loc[0]['symptoms'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Lumps near breast or underarm'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSPa62zJb1A7",
        "outputId": "360a6440-072e-48c3-c395-2a88a70e7e5d"
      },
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_lg==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz (827.9MB)\n",
            "\u001b[K     |████████████████████████████████| 827.9MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (50.3.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2020.11.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.4.0)\n",
            "Building wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.2.5-cp36-none-any.whl size=829180944 sha256=ac91e5097179269321d00433ccb5c315929e2872f0db3fd52a2c1a2e50f568bd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-po68xlxv/wheels/2a/c1/a6/fc7a877b1efca9bc6a089d6f506f16d3868408f9ff89f8dbfc\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEruZWrSkSRl"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_lg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0ZHt-yDkUae",
        "outputId": "c4efa540-387a-4228-a3cd-f890a1055a29"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lumps near breast or underarm\n",
            "Swelling on breast\n",
            "Irritation of breast skin\n",
            "Redness or flaky skin near nipples\n",
            "Nipple discharge other than milk, including blood\n",
            "Change in shape and size of breast\n",
            "Any pain in breast area\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYI1lXJtkW0E",
        "outputId": "1583eea1-036e-440d-e110-596178d8d9e0"
      },
      "source": [
        "import nltk \n",
        "import string \n",
        "import re \n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def text_lowercase(text): \n",
        "    return text.lower() \n",
        "\n",
        "def remove_numbers(text): \n",
        "    result = re.sub(r'\\d+', '', text) \n",
        "    return result \n",
        "  \n",
        "import inflect \n",
        "p = inflect.engine() \n",
        "   \n",
        "def convert_number(text):  \n",
        "    temp_str = text.split() \n",
        "    new_string = [] \n",
        "  \n",
        "    for word in temp_str: \n",
        "        if word.isdigit(): \n",
        "            temp = p.number_to_words(word) \n",
        "            new_string.append(temp) \n",
        "        else: \n",
        "            new_string.append(word) \n",
        "    temp_str = ' '.join(new_string) \n",
        "    return temp_str \n",
        "\n",
        "def remove_punctuation(text): \n",
        "    translator = str.maketrans('', '', string.punctuation) \n",
        "    return text.translate(translator) \n",
        "\n",
        "def remove_whitespace(text): \n",
        "    return  \" \".join(text.split()) \n",
        "\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize \n",
        "  \n",
        "def remove_stopwords(text): \n",
        "    stop_words = set(stopwords.words(\"english\")) \n",
        "    word_tokens = word_tokenize(text) \n",
        "    filtered_text = [word for word in word_tokens if word not in stop_words] \n",
        "    return filtered_text \n",
        "\n",
        "from nltk.stem.porter import PorterStemmer \n",
        "from nltk.tokenize import word_tokenize \n",
        "stemmer = PorterStemmer() \n",
        "\n",
        "def stem_words(word_tokens):  \n",
        "    stems = [stemmer.stem(word) for word in word_tokens] \n",
        "    return stems \n",
        "\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from nltk.tokenize import word_tokenize \n",
        "lemmatizer = WordNetLemmatizer() \n",
        "def lemmatize_word(word_tokens): \n",
        "    lemmas = [lemmatizer.lemmatize(word, pos ='v') for word in word_tokens] \n",
        "    return lemmas \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WlEM0MBhKmG"
      },
      "source": [
        "def text_preprocessed(text):\n",
        "  text = text_lowercase(text)\n",
        "  text = convert_number(text)\n",
        "  text = remove_punctuation(text)\n",
        "  text = remove_stopwords(text)\n",
        "  text = stem_words(text)\n",
        "  text = lemmatize_word(text)\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7Tg3XdOIj4l",
        "outputId": "91d5390c-2a8d-42ba-df6b-98d690fc46ae"
      },
      "source": [
        "text = text_preprocessed('hii everyone,welcome you all to my best friend hitika marriage. I love her and am so happy for her,I wish she will have a beautiful life ahead and will not forget us.')\n",
        "print(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['hii', 'everyonewelcom', 'best', 'friend', 'hitika', 'marriag', 'love', 'happi', 'heri', 'wish', 'beauti', 'life', 'ahead', 'forget', 'us']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZEDL42kK8Zb"
      },
      "source": [
        "symptom_disease = {}\n",
        "lin = []\n",
        "for i in np.arange(0,6):\n",
        "  symptom_disease[tejas.loc[i]['name']] = []\n",
        "  for j in tejas.loc[i]['symptoms']:\n",
        "    text = text_preprocessed(j)\n",
        "    for t in text:\n",
        "      symptom_disease[tejas.loc[i]['name']].append(t)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrjjgAc3xFEy",
        "outputId": "68e05a05-8347-4153-f99a-fd20a26bdd1f"
      },
      "source": [
        "print(symptom_disease['breast cancer'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['lump', 'near', 'breast', 'underarm', 'swell', 'breast', 'irrit', 'breast', 'skin', 'red', 'flaki', 'skin', 'near', 'nippl', 'nippl', 'discharg', 'milk', 'includ', 'blood', 'chang', 'shape', 'size', 'breast', 'pain', 'breast', 'area']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFs0xFXUyHBU"
      },
      "source": [
        "for i in np.arange(0,6):\n",
        "  tejas.loc[i]['symptoms'] = symptom_disease[tejas.loc[i]['name']]\n",
        "\n",
        "tejas.to_csv('tejas.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkIPOOCiRi3b",
        "outputId": "a4fc8abd-d951-42be-95e9-b20a902eeedf"
      },
      "source": [
        "print(\"Enter two space-separated words\") \n",
        "words = input() \n",
        "  \n",
        "tokens = nlp(words)\n",
        "token1, token2 = tokens[0], tokens[1] \n",
        "  \n",
        "print(\"Similarity:\", token1.similarity(token2))  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter two space-separated words\n",
            "fever vomit\n",
            "Similarity: 0.40331587\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKC-PKNmirOU",
        "outputId": "794204b4-5e37-4f4e-adfc-62cb2ff12958"
      },
      "source": [
        "import gensim\n",
        "from nltk.corpus import lin_thesaurus\n",
        "nltk.download('lin_thesaurus')\n",
        "\n",
        "import pickle\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d leadbest/googlenewsvectorsnegative300"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package lin_thesaurus to /root/nltk_data...\n",
            "[nltk_data]   Package lin_thesaurus is already up-to-date!\n",
            "Downloading googlenewsvectorsnegative300.zip to /content\n",
            "100% 3.17G/3.17G [00:54<00:00, 53.8MB/s]\n",
            "100% 3.17G/3.17G [00:54<00:00, 62.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMXhTbl6cd97",
        "outputId": "27c09aa6-f2ed-475f-8a35-24af128dfb65"
      },
      "source": [
        "!unzip googlenewsvectorsnegative300.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  googlenewsvectorsnegative300.zip\n",
            "  inflating: GoogleNews-vectors-negative300.bin  \n",
            "  inflating: GoogleNews-vectors-negative300.bin.gz  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmftiqW_bmw3"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "model = KeyedVectors.load_word2vec_format('/content/GoogleNews-vectors-negative300.bin',binary=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ij5Dq1gQg30m",
        "outputId": "a638ab36-150d-4fe2-f76a-26d0a9cc85c4"
      },
      "source": [
        "model.wv['fever']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.3125    ,  0.06884766, -0.09863281, -0.0100708 , -0.37109375,\n",
              "       -0.11328125, -0.25976562, -0.4296875 , -0.22949219, -0.44335938,\n",
              "       -0.16699219, -0.43359375,  0.1796875 ,  0.05053711, -0.14648438,\n",
              "        0.23144531,  0.14160156,  0.13574219,  0.28710938, -0.28320312,\n",
              "       -0.15429688, -0.22558594,  0.26171875,  0.00622559, -0.28710938,\n",
              "       -0.21289062,  0.12890625, -0.17578125,  0.25585938, -0.11132812,\n",
              "       -0.02368164, -0.00463867,  0.0402832 , -0.03588867, -0.38476562,\n",
              "       -0.08203125, -0.07226562, -0.26953125,  0.49023438,  0.27148438,\n",
              "        0.19726562, -0.421875  , -0.14257812,  0.02404785,  0.30859375,\n",
              "        0.10302734,  0.0135498 , -0.12255859, -0.08398438, -0.14648438,\n",
              "       -0.15625   ,  0.53125   , -0.35546875,  0.26953125,  0.11962891,\n",
              "       -0.06201172,  0.12890625, -0.32226562,  0.12695312,  0.30664062,\n",
              "        0.19433594, -0.00227356, -0.12109375,  0.00157928,  0.24414062,\n",
              "       -0.06884766, -0.0402832 ,  0.04052734,  0.19921875,  0.28710938,\n",
              "       -0.00878906, -0.01806641,  0.37695312,  0.25976562, -0.02331543,\n",
              "        0.03759766,  0.3203125 , -0.03198242,  0.24316406,  0.36132812,\n",
              "        0.34765625,  0.10498047, -0.16308594, -0.09423828,  0.12255859,\n",
              "       -0.18652344, -0.02526855, -0.05639648,  0.34570312, -0.32226562,\n",
              "       -0.09179688,  0.03662109, -0.3203125 , -0.07958984, -0.09472656,\n",
              "        0.20410156,  0.49804688,  0.05249023,  0.09521484,  0.4140625 ,\n",
              "        0.0390625 , -0.35742188,  0.012146  , -0.37890625, -0.10400391,\n",
              "       -0.28125   , -0.03393555,  0.2109375 ,  0.19335938, -0.21484375,\n",
              "        0.19628906,  0.09228516,  0.27929688, -0.26953125,  0.20605469,\n",
              "        0.0267334 , -0.003479  ,  0.19921875, -0.26953125, -0.20800781,\n",
              "       -0.38476562, -0.24902344,  0.03710938, -0.15234375, -0.01525879,\n",
              "       -0.07421875,  0.32617188, -0.13867188,  0.16601562, -0.09130859,\n",
              "       -0.24707031,  0.02636719, -0.14355469, -0.37890625, -0.42382812,\n",
              "        0.49414062, -0.375     ,  0.12988281, -0.12597656,  0.43359375,\n",
              "       -0.20410156, -0.02978516,  0.10107422,  0.13769531,  0.15722656,\n",
              "        0.02929688,  0.0625    , -0.0559082 ,  0.02331543, -0.54296875,\n",
              "        0.07470703,  0.05224609,  0.13867188,  0.13378906, -0.24902344,\n",
              "       -0.06542969,  0.19335938, -0.57421875, -0.28125   , -0.22558594,\n",
              "       -0.03344727, -0.29101562,  0.0189209 , -0.20019531, -0.06201172,\n",
              "        0.0378418 ,  0.02868652, -0.09619141,  0.24121094,  0.10107422,\n",
              "       -0.15332031,  0.5078125 ,  0.11474609, -0.3046875 , -0.09863281,\n",
              "       -0.09765625, -0.03955078,  0.17480469, -0.25      , -0.03979492,\n",
              "        0.11572266, -0.13964844,  0.00328064,  0.09082031,  0.30859375,\n",
              "       -0.07470703, -0.20898438, -0.00325012,  0.00133514,  0.34375   ,\n",
              "       -0.35546875,  0.01367188, -0.0612793 ,  0.46875   , -0.36132812,\n",
              "        0.328125  ,  0.10791016,  0.18847656,  0.02685547, -0.1875    ,\n",
              "        0.26953125,  0.07128906, -0.07519531,  0.13378906,  0.18945312,\n",
              "       -0.4453125 , -0.11230469, -0.07128906,  0.34179688,  0.32617188,\n",
              "       -0.16992188,  0.07275391,  0.09228516,  0.20117188, -0.37109375,\n",
              "       -0.16894531, -0.3828125 , -0.22460938, -0.10498047, -0.19335938,\n",
              "        0.22167969,  0.07177734,  0.12011719,  0.5078125 , -0.1328125 ,\n",
              "        0.04467773, -0.14355469,  0.1484375 , -0.02453613,  0.31054688,\n",
              "       -0.078125  , -0.11181641,  0.08203125, -0.08642578, -0.25      ,\n",
              "        0.05004883, -0.02575684,  0.20507812,  0.51953125,  0.02514648,\n",
              "        0.05883789, -0.31835938,  0.30273438,  0.23925781,  0.25195312,\n",
              "        0.25585938, -0.16503906, -0.06933594,  0.16015625, -0.16601562,\n",
              "        0.3046875 ,  0.21484375,  0.41210938,  0.25195312,  0.12353516,\n",
              "        0.24707031, -0.32421875,  0.27148438, -0.04296875,  0.02514648,\n",
              "       -0.00473022, -0.01879883,  0.00836182,  0.04711914, -0.08984375,\n",
              "        0.12451172, -0.12109375, -0.18847656,  0.41210938, -0.05737305,\n",
              "       -0.06396484,  0.296875  ,  0.203125  , -0.296875  , -0.0625    ,\n",
              "       -0.54296875, -0.06591797,  0.22070312, -0.13964844,  0.18261719,\n",
              "        0.21972656, -0.13574219, -0.11621094,  0.06347656,  0.07128906,\n",
              "       -0.00714111,  0.20214844,  0.296875  ,  0.00848389,  0.06298828,\n",
              "        0.00112152, -0.24609375, -0.09423828, -0.11230469,  0.5625    ,\n",
              "        0.06445312, -0.23730469,  0.19628906,  0.16210938,  0.23730469],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjxP9VP_jsT4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8173b478-ff04-4747-a353-21d13851d734"
      },
      "source": [
        "model.wv.similarity('vagina','breast')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4271729"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr_zbn5zR9Zj"
      },
      "source": [
        "model.save('/content/gensim_model')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdIZ4u9jpNXX"
      },
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "new_model = KeyedVectors.load('/content/gensim_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "TLg828aIrr2k",
        "outputId": "339fe74f-2cc9-4f63-976c-095d68fe874e"
      },
      "source": [
        "new_model.wv.similarity('fever','headpain')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-9bbb4d153ff5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fever'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'headpain'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36msimilarity\u001b[0;34m(self, w1, w2)\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m         \"\"\"\n\u001b[0;32m--> 992\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munitvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munitvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mn_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mws1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mws2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"word 'headpain' not in vocabulary\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5znNeVQu16Sg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JoSOhsuz_IU",
        "outputId": "1b7e7dd9-cebc-430c-f5af-d77e70e2ef42"
      },
      "source": [
        "words = input()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i have fever and I have cough and doing vomiting.I am also feeling nervous\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPWxWdvgww5n"
      },
      "source": [
        "def probable_disease(input_data):\n",
        "  similarity = {}\n",
        "  for i in np.arange(0,6):\n",
        "    similarity[tejas.loc[i]['name']] = 0;\n",
        "    for j in tejas.loc[i]['symptoms']:\n",
        "      for t in input_data:\n",
        "        try:\n",
        "          similarity[tejas.loc[i]['name']] = similarity[tejas.loc[i]['name']] + new_model.wv.similarity(j,t)/(len(tejas.loc[i]['symptoms'])*len(input_data))\n",
        "        except KeyError:\n",
        "          continue\n",
        "\n",
        "  prob_dis = sorted(similarity.items(),key=lambda x: x[1], reverse=True)\n",
        "\n",
        "  for i in prob_dis[:3]:\n",
        "    print(i[0])\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7wlXZpn4omX",
        "outputId": "b9766c13-d59e-414e-debe-614ab6c02f21"
      },
      "source": [
        "input_data = text_preprocessed(words)\n",
        "probable_disease(input_data)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pneumonia\n",
            "covid-19\n",
            "cardiovascular disease\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXI4wwWqWMIZ"
      },
      "source": [
        "import nltk \n",
        "import string \n",
        "import re \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def text_lowercase(text): \n",
        "    return text.lower() \n",
        "\n",
        "def remove_numbers(text): \n",
        "    result = re.sub(r'\\d+', '', text) \n",
        "    return result \n",
        "  \n",
        "import inflect \n",
        "p = inflect.engine() \n",
        "   \n",
        "def convert_number(text):  \n",
        "    temp_str = text.split() \n",
        "    new_string = [] \n",
        "  \n",
        "    for word in temp_str: \n",
        "        if word.isdigit(): \n",
        "            temp = p.number_to_words(word) \n",
        "            new_string.append(temp) \n",
        "        else: \n",
        "            new_string.append(word) \n",
        "    temp_str = ' '.join(new_string) \n",
        "    return temp_str \n",
        "\n",
        "def remove_punctuation(text): \n",
        "    translator = str.maketrans('', '', string.punctuation) \n",
        "    return text.translate(translator) \n",
        "\n",
        "def remove_whitespace(text): \n",
        "    return  \" \".join(text.split()) \n",
        "\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize \n",
        "  \n",
        "def remove_stopwords(text): \n",
        "    stop_words = set(stopwords.words(\"english\")) \n",
        "    word_tokens = word_tokenize(text) \n",
        "    filtered_text = [word for word in word_tokens if word not in stop_words] \n",
        "    return filtered_text \n",
        "\n",
        "from nltk.stem.porter import PorterStemmer \n",
        "from nltk.tokenize import word_tokenize \n",
        "stemmer = PorterStemmer() \n",
        "\n",
        "def stem_words(word_tokens):  \n",
        "    stems = [stemmer.stem(word) for word in word_tokens] \n",
        "    return stems \n",
        "\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from nltk.tokenize import word_tokenize \n",
        "lemmatizer = WordNetLemmatizer() \n",
        "def lemmatize_word(word_tokens): \n",
        "    lemmas = [lemmatizer.lemmatize(word, pos ='v') for word in word_tokens] \n",
        "    return lemmas \n",
        "\n",
        "\n",
        "def text_preprocessed(text):\n",
        "  text = text_lowercase(text)\n",
        "  text = convert_number(text)\n",
        "  text = remove_punctuation(text)\n",
        "  text = remove_stopwords(text)\n",
        "  text = stem_words(text)\n",
        "  text = lemmatize_word(text)\n",
        "  return text\n",
        "\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "new_model = KeyedVectors.load('/content/gensim_model')\n",
        "\n",
        "\n",
        "def probable_disease(input_data):\n",
        "  similarity = {}\n",
        "  for i in np.arange(0,6):\n",
        "    similarity[tejas.loc[i]['name']] = 0;\n",
        "    for j in tejas.loc[i]['symptoms']:\n",
        "      for t in input_data:\n",
        "        try:\n",
        "          similarity[tejas.loc[i]['name']] = similarity[tejas.loc[i]['name']] + new_model.wv.similarity(j,t)/(len(tejas.loc[i]['symptoms'])*len(input_data))\n",
        "        except KeyError:\n",
        "          continue\n",
        "\n",
        "  prob_dis = sorted(similarity.items(),key=lambda x: x[1], reverse=True)\n",
        "\n",
        "  for i in prob_dis[:3]:\n",
        "    print(i[0])\n",
        "\n",
        "tejas = pd.read_csv('tejas.csv')\n",
        "\n",
        "\n",
        "import speech_recognition as sr\n",
        "sr.__version__\n",
        "\n",
        "r = sr.Recognizer()\n",
        "\n",
        "with sr.Microphone() as source:\n",
        "    print(\"Talk\")\n",
        "    audio_text = r.listen(source)\n",
        "    print(\"Time over, thanks\")\n",
        "    try:\n",
        "        print(\"Text: \"+r.recognize_google(audio_text))\n",
        "\t  text = r.recognize_google(audio_text)\n",
        "    except:\n",
        "         print(\"Sorry, I did not get that\")\n",
        "\n",
        "\n",
        "\n",
        "input_data = text_preprocessed(text)\n",
        "\n",
        "probable_disease(input_data)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}